{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data1\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for CRNN\n",
    "class Dataset_CRNN(data.Dataset):\n",
    "    \"Characterizes a dataset for PyTorch\"\n",
    "    def __init__(self, data_path, frame_length=10, transform=None):\n",
    "        \"Initialization\"\n",
    "        self.transform = transform\n",
    "        #self.frames = frames\n",
    "        self.folders = data_path\n",
    "        self.frames = frame_length #For our case since we are computing 10 frames always\n",
    "\n",
    "    def __len__(self):\n",
    "        \"Denotes the total number of samples\"\n",
    "        return len(os.listdir(self.folders))\n",
    "\n",
    "    def read_images(self, data_path, use_transform):\n",
    "        X = []\n",
    "        file_name = \"\"\n",
    "        for i in os.listdir(data_path):\n",
    "            file_name = i\n",
    "            image = Image.open(os.path.join(data_path,i))\n",
    "            \n",
    "            #print(image.shape)\n",
    "            if use_transform is not None:\n",
    "                image = use_transform(image)\n",
    "                #print(image.size)\n",
    "            image = torch.from_numpy(np.asarray(image))\n",
    "            X.append(image)\n",
    "        X = torch.stack(X, dim=0)\n",
    "\n",
    "        return X, file_name\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_path = os.path.join(self.folders,os.listdir(self.folders)[index])\n",
    "              \n",
    "        # Load data\n",
    "        X, file_name = self.read_images(data_path, self.transform)                     # (input) spatial images\n",
    "        \n",
    "        y = np.ones(self.frames)\n",
    "        if 'real' in data_path:\n",
    "            y = np.zeros(self.frames)\n",
    "        #print(\"Folder is {}\".format(data_path))\n",
    "        #print(X.shape)\n",
    "        return X, torch.from_numpy(y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_IMG_TRAIN = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.RandomResizedCrop(128),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "    transforms.ToPILImage()\n",
    "    \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_IMG_VAL = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.RandomResizedCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "    transforms.ToPILImage()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_path = '/home/chinmay/datatset/deepfake_split/train'\n",
    "train_data = Dataset_CRNN(train_path, transform=TRANSFORM_IMG_TRAIN, frame_length=30 )\n",
    "# for step, (x, y) in enumerate(data):\n",
    "#     print(x.shape)\n",
    "val_path = '/home/chinmay/datatset/deepfake_split/val'\n",
    "val_data = Dataset_CRNN(val_path, transform=TRANSFORM_IMG_VAL, frame_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 80\n",
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "log_interval = 10\n",
    "img_x, img_y = 96,96#128,128#256, 256  # resize video 2d frame size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is use_cuda True\n"
     ]
    }
   ],
   "source": [
    "# Detect devices\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "print(\"Is use_cuda\", use_cuda)\n",
    "# Now load the dataset\n",
    "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "# Load the dataset\n",
    "\n",
    "train_loader = data1.DataLoader(train_data, **params)\n",
    "valid_loader = data1.DataLoader(val_data, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_median(numpy_array = []): #This is expected to take an array of array. So,\n",
    "    #print(\"Input array is {}\".format(numpy_array))\n",
    "    output = []\n",
    "    confidence_scores = []\n",
    "    for array in numpy_array:\n",
    "        counts = np.bincount(array)\n",
    "        output.append(np.argmax(counts))\n",
    "        # Let us compute the confidence of the scores\n",
    "        # since frames are independent, our confidence is purely based on the number\n",
    "        # of frames our model thinks is belonging to a specific category\n",
    "        # the confidence of individual frame prediction is not taken into consideration\n",
    "        # and this portion is debatable....\n",
    "        frame_set_pred = np.sort(counts)[-1]\n",
    "        confidence = frame_set_pred/sum(counts)\n",
    "        confidence_scores.append(confidence)\n",
    "    return torch.from_numpy(np.asarray(output)).type(torch.LongTensor), torch.from_numpy(np.asarray(confidence_scores)).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model paths\n",
    "writer_train = SummaryWriter('/home/chinmay/training-results/conv3D_refined/train')\n",
    "writer_test = SummaryWriter('/home/chinmay/training-results/conv3D_refined/test')\n",
    "save_model_path = \"/home/chinmay/model_weights/conv3D/\"\n",
    "\n",
    "\n",
    "\n",
    "# Select which frame to begin & end in videos\n",
    "begin_frame, end_frame, skip_frame = 1, 10, 1\n",
    "\n",
    "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
    "    # set model as training mode\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    scores = []\n",
    "    N_count = 0   # counting total trained sample in one epoch\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        # distribute data to device\n",
    "        #X, y = X.to(device), y.to(device)\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        #print(\"The label is \",y)\n",
    "        N_count += X.size(0)\n",
    "        #print(\"The size is \",X.size())\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)  # output size = (batch, number of classes)\n",
    "        y, _ = find_median(y) #This is necessary as now only single label output for entire frame\n",
    "        y = y.to(device)\n",
    "        #print(y)\n",
    "        #print(y.shape)\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # to compute accuracy\n",
    "        y_pred = torch.max(output, 1)[1]  # y_pred != output\n",
    "        step_score = accuracy_score(y.cpu().data.squeeze().numpy(), y_pred.cpu().data.squeeze().numpy())\n",
    "        scores.append(step_score)         # computed on CPU\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "                 \n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accu: {:.2f}%'.format(\n",
    "                epoch + 1, N_count, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item(), 100 * step_score))\n",
    "         \n",
    "    return np.mean(losses), np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, device, optimizer, test_loader):\n",
    "    # set model as testing mode\n",
    "    model.eval()\n",
    "\n",
    "    all_y = []\n",
    "    all_y_pred = []\n",
    "    test_loss = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            # distribute data to device\n",
    "            #X, y = X.to(device), y.to(device)\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            output = model(X)\n",
    "\n",
    "            y, _ = find_median(y) #This is necessary as now only single label output for entire frame\n",
    "            y = y.to(device)\n",
    "            loss = F.cross_entropy(output, y)\n",
    "            test_loss.append(loss.item())                 # sum up batch loss\n",
    "            y_pred = output.max(1, keepdim=True)[1]  # (y_pred != output) get the index of the max log-probability\n",
    "            \n",
    "            # collect all y and y_pred in all batches\n",
    "            all_y.extend(y)\n",
    "            all_y_pred.extend(y_pred)\n",
    "\n",
    "    test_loss = np.mean(test_loss)\n",
    "\n",
    "    # to compute accuracy\n",
    "#     all_y = torch.stack(all_y, dim=0)\n",
    "#     all_y_pred = torch.stack(all_y_pred, dim=0)\n",
    "    all_y = torch.stack(all_y, dim=0)\n",
    "    all_y_pred = torch.stack(all_y_pred, dim=0)\n",
    "    test_score = accuracy_score(all_y.cpu().data.squeeze().numpy(), all_y_pred.cpu().data.squeeze().numpy())\n",
    "\n",
    "    # show information\n",
    "    print('\\nTest set ({:d} samples): Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(len(all_y), test_loss, 100* test_score))\n",
    "\n",
    "    # save Pytorch models of best record\n",
    "    torch.save(model.state_dict(), os.path.join(save_model_path, 'cnn3d{}.pth'.format(epoch + 1)))  # save spatial_encoder\n",
    "    torch.save(optimizer.state_dict(), os.path.join(save_model_path, 'cnn3d_epoch{}.pth'.format(epoch + 1)))      # save optimizer\n",
    "    print(\"Epoch {} model saved!\".format(epoch + 1))\n",
    "\n",
    "\n",
    "    return test_loss, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [40/416 (10%)]\tLoss: 6.450998, Accu: 0.00%\n",
      "Train Epoch: 1 [80/416 (19%)]\tLoss: 5.884359, Accu: 0.00%\n",
      "Train Epoch: 1 [120/416 (29%)]\tLoss: 5.142314, Accu: 50.00%\n",
      "Train Epoch: 1 [160/416 (38%)]\tLoss: 4.568912, Accu: 0.00%\n",
      "Train Epoch: 1 [200/416 (48%)]\tLoss: 3.708913, Accu: 50.00%\n",
      "Train Epoch: 1 [240/416 (58%)]\tLoss: 2.635862, Accu: 50.00%\n",
      "Train Epoch: 1 [280/416 (67%)]\tLoss: 2.074915, Accu: 50.00%\n",
      "Train Epoch: 1 [320/416 (77%)]\tLoss: 2.045294, Accu: 50.00%\n",
      "Train Epoch: 1 [360/416 (87%)]\tLoss: 2.539561, Accu: 25.00%\n",
      "Train Epoch: 1 [400/416 (96%)]\tLoss: 2.145723, Accu: 25.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 3.6529, Accuracy: 58.30%\n",
      "\n",
      "Epoch 1 model saved!\n",
      "Train Epoch: 2 [40/416 (10%)]\tLoss: 3.000574, Accu: 0.00%\n",
      "Train Epoch: 2 [80/416 (19%)]\tLoss: 1.030439, Accu: 75.00%\n",
      "Train Epoch: 2 [120/416 (29%)]\tLoss: 1.132107, Accu: 75.00%\n",
      "Train Epoch: 2 [160/416 (38%)]\tLoss: 0.984558, Accu: 75.00%\n",
      "Train Epoch: 2 [200/416 (48%)]\tLoss: 0.404924, Accu: 100.00%\n",
      "Train Epoch: 2 [240/416 (58%)]\tLoss: 1.455803, Accu: 50.00%\n",
      "Train Epoch: 2 [280/416 (67%)]\tLoss: 1.771480, Accu: 50.00%\n",
      "Train Epoch: 2 [320/416 (77%)]\tLoss: 0.932396, Accu: 75.00%\n",
      "Train Epoch: 2 [360/416 (87%)]\tLoss: 1.008035, Accu: 75.00%\n",
      "Train Epoch: 2 [400/416 (96%)]\tLoss: 1.765691, Accu: 50.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 3.0303, Accuracy: 58.72%\n",
      "\n",
      "Epoch 2 model saved!\n",
      "Train Epoch: 3 [40/416 (10%)]\tLoss: 2.280633, Accu: 0.00%\n",
      "Train Epoch: 3 [80/416 (19%)]\tLoss: 0.900764, Accu: 75.00%\n",
      "Train Epoch: 3 [120/416 (29%)]\tLoss: 1.170571, Accu: 75.00%\n",
      "Train Epoch: 3 [160/416 (38%)]\tLoss: 1.757027, Accu: 25.00%\n",
      "Train Epoch: 3 [200/416 (48%)]\tLoss: 1.328479, Accu: 50.00%\n",
      "Train Epoch: 3 [240/416 (58%)]\tLoss: 1.645032, Accu: 25.00%\n",
      "Train Epoch: 3 [280/416 (67%)]\tLoss: 1.145375, Accu: 50.00%\n",
      "Train Epoch: 3 [320/416 (77%)]\tLoss: 0.845829, Accu: 75.00%\n",
      "Train Epoch: 3 [360/416 (87%)]\tLoss: 0.433583, Accu: 100.00%\n",
      "Train Epoch: 3 [400/416 (96%)]\tLoss: 1.008038, Accu: 50.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 2.6963, Accuracy: 54.04%\n",
      "\n",
      "Epoch 3 model saved!\n",
      "Train Epoch: 4 [40/416 (10%)]\tLoss: 0.974923, Accu: 50.00%\n",
      "Train Epoch: 4 [80/416 (19%)]\tLoss: 0.759100, Accu: 75.00%\n",
      "Train Epoch: 4 [120/416 (29%)]\tLoss: 0.520192, Accu: 100.00%\n",
      "Train Epoch: 4 [160/416 (38%)]\tLoss: 0.605216, Accu: 75.00%\n",
      "Train Epoch: 4 [200/416 (48%)]\tLoss: 0.859097, Accu: 50.00%\n",
      "Train Epoch: 4 [240/416 (58%)]\tLoss: 0.829331, Accu: 25.00%\n",
      "Train Epoch: 4 [280/416 (67%)]\tLoss: 0.852224, Accu: 50.00%\n",
      "Train Epoch: 4 [320/416 (77%)]\tLoss: 0.672233, Accu: 75.00%\n",
      "Train Epoch: 4 [360/416 (87%)]\tLoss: 1.073018, Accu: 25.00%\n",
      "Train Epoch: 4 [400/416 (96%)]\tLoss: 0.692104, Accu: 50.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 2.2318, Accuracy: 41.70%\n",
      "\n",
      "Epoch 4 model saved!\n",
      "Train Epoch: 5 [40/416 (10%)]\tLoss: 0.622393, Accu: 75.00%\n",
      "Train Epoch: 5 [80/416 (19%)]\tLoss: 0.673533, Accu: 75.00%\n",
      "Train Epoch: 5 [120/416 (29%)]\tLoss: 0.660547, Accu: 75.00%\n",
      "Train Epoch: 5 [160/416 (38%)]\tLoss: 0.800344, Accu: 50.00%\n",
      "Train Epoch: 5 [200/416 (48%)]\tLoss: 0.894323, Accu: 50.00%\n",
      "Train Epoch: 5 [240/416 (58%)]\tLoss: 0.657006, Accu: 75.00%\n",
      "Train Epoch: 5 [280/416 (67%)]\tLoss: 0.798884, Accu: 75.00%\n",
      "Train Epoch: 5 [320/416 (77%)]\tLoss: 0.978234, Accu: 50.00%\n",
      "Train Epoch: 5 [360/416 (87%)]\tLoss: 0.667303, Accu: 75.00%\n",
      "Train Epoch: 5 [400/416 (96%)]\tLoss: 0.738211, Accu: 75.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 2.1940, Accuracy: 39.57%\n",
      "\n",
      "Epoch 5 model saved!\n",
      "Train Epoch: 6 [40/416 (10%)]\tLoss: 0.793763, Accu: 50.00%\n",
      "Train Epoch: 6 [80/416 (19%)]\tLoss: 0.801199, Accu: 25.00%\n",
      "Train Epoch: 6 [120/416 (29%)]\tLoss: 0.740309, Accu: 50.00%\n",
      "Train Epoch: 6 [160/416 (38%)]\tLoss: 0.332285, Accu: 100.00%\n",
      "Train Epoch: 6 [200/416 (48%)]\tLoss: 0.696864, Accu: 75.00%\n",
      "Train Epoch: 6 [240/416 (58%)]\tLoss: 0.698848, Accu: 50.00%\n",
      "Train Epoch: 6 [280/416 (67%)]\tLoss: 0.534331, Accu: 75.00%\n",
      "Train Epoch: 6 [320/416 (77%)]\tLoss: 0.495825, Accu: 100.00%\n",
      "Train Epoch: 6 [360/416 (87%)]\tLoss: 1.036296, Accu: 0.00%\n",
      "Train Epoch: 6 [400/416 (96%)]\tLoss: 0.682711, Accu: 75.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 2.0557, Accuracy: 40.00%\n",
      "\n",
      "Epoch 6 model saved!\n",
      "Train Epoch: 7 [40/416 (10%)]\tLoss: 0.814481, Accu: 25.00%\n",
      "Train Epoch: 7 [80/416 (19%)]\tLoss: 0.653262, Accu: 50.00%\n",
      "Train Epoch: 7 [120/416 (29%)]\tLoss: 0.621603, Accu: 75.00%\n",
      "Train Epoch: 7 [160/416 (38%)]\tLoss: 0.765494, Accu: 50.00%\n",
      "Train Epoch: 7 [200/416 (48%)]\tLoss: 0.765768, Accu: 50.00%\n",
      "Train Epoch: 7 [240/416 (58%)]\tLoss: 0.726454, Accu: 50.00%\n",
      "Train Epoch: 7 [280/416 (67%)]\tLoss: 0.559942, Accu: 75.00%\n",
      "Train Epoch: 7 [320/416 (77%)]\tLoss: 0.685580, Accu: 50.00%\n",
      "Train Epoch: 7 [360/416 (87%)]\tLoss: 0.654300, Accu: 50.00%\n",
      "Train Epoch: 7 [400/416 (96%)]\tLoss: 0.390629, Accu: 100.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 1.9084, Accuracy: 42.55%\n",
      "\n",
      "Epoch 7 model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-60:\n",
      "Process Process-58:\n",
      "Process Process-59:\n",
      "Traceback (most recent call last):\n",
      "Process Process-57:\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/chinmay/anaconda3/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9f0bfc741ce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# train, test model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mepoch_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_test_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1b7ab9fa525c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(log_interval, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# distribute data to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#X, y = X.to(device), y.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m#print(\"The label is \",y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mN_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create model\n",
    "#cnn3d = CNN3D(t_dim=10, img_x=img_x, img_y=img_y,\n",
    "#              drop_p=dropout, fc_hidden1=fc_hidden1,  fc_hidden2=fc_hidden2, num_classes=2)\n",
    "\n",
    "from Res3D import C3D\n",
    "cnn3d = C3D(img_dim=128, frames=30, dropout=0.4)\n",
    "\n",
    "cnn3d.cuda()\n",
    "# Parallelize model to multiple GPUs\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    cnn3d = nn.DataParallel(cnn3d)\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn3d.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
    "\n",
    "\n",
    "# record training process\n",
    "epoch_train_losses = []\n",
    "epoch_train_scores = []\n",
    "epoch_test_losses = []\n",
    "epoch_test_scores = []\n",
    "\n",
    "\n",
    "# start training\n",
    "for epoch in range(epochs):\n",
    "    # train, test model\n",
    "    train_losses, train_scores = train(log_interval, cnn3d, device, train_loader, optimizer, epoch)\n",
    "    epoch_test_loss, epoch_test_score = validation(cnn3d, device, optimizer, valid_loader)\n",
    "\n",
    "    # save all train test results\n",
    "    # save results\n",
    "    writer_train.add_scalar('loss',train_losses,epoch+1)\n",
    "    writer_train.add_scalar('score',train_scores,epoch+1)\n",
    "    writer_test.add_scalar('loss',epoch_test_loss,epoch+1)\n",
    "    writer_test.add_scalar('score',epoch_test_score,epoch+1)\n",
    "    \n",
    "    \n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
