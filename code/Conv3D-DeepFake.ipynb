{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data1\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for CRNN\n",
    "class Dataset_CRNN(data.Dataset):\n",
    "    \"Characterizes a dataset for PyTorch\"\n",
    "    def __init__(self, data_path, frame_length=10, transform=None):\n",
    "        \"Initialization\"\n",
    "        self.transform = transform\n",
    "        #self.frames = frames\n",
    "        self.folders = data_path\n",
    "        self.frames = frame_length #For our case since we are computing 10 frames always\n",
    "\n",
    "    def __len__(self):\n",
    "        \"Denotes the total number of samples\"\n",
    "        return len(os.listdir(self.folders))\n",
    "\n",
    "    def read_images(self, data_path, use_transform):\n",
    "        X = []\n",
    "        file_name = \"\"\n",
    "        for i in os.listdir(data_path):\n",
    "            file_name = i\n",
    "            image = Image.open(os.path.join(data_path,i))\n",
    "            \n",
    "            #print(image.shape)\n",
    "            if use_transform is not None:\n",
    "                image = use_transform(image)\n",
    "                #print(image.size)\n",
    "            image = torch.from_numpy(np.asarray(image))\n",
    "            X.append(image)\n",
    "        X = torch.stack(X, dim=0)\n",
    "\n",
    "        return X, file_name\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_path = os.path.join(self.folders,os.listdir(self.folders)[index])\n",
    "              \n",
    "        # Load data\n",
    "        X, file_name = self.read_images(data_path, self.transform)                     # (input) spatial images\n",
    "        \n",
    "        y = np.ones(self.frames)\n",
    "        if 'real' in data_path:\n",
    "            y = np.zeros(self.frames)\n",
    "        #print(\"Folder is {}\".format(data_path))\n",
    "        #print(X.shape)\n",
    "        return X, torch.from_numpy(y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_IMG_TRAIN = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.RandomResizedCrop(256)\n",
    "    \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_IMG_VAL = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(256)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_path = '/home/chinmay/datatset/deepfake_split/train'\n",
    "train_data = Dataset_CRNN(train_path, transform=TRANSFORM_IMG_TRAIN, frame_length=30 )\n",
    "# for step, (x, y) in enumerate(data):\n",
    "#     print(x.shape)\n",
    "val_path = '/home/chinmay/datatset/deepfake_split/val'\n",
    "val_data = Dataset_CRNN(val_path, transform=TRANSFORM_IMG_VAL, frame_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 80\n",
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "log_interval = 10\n",
    "img_x, img_y = 96,96#128,128#256, 256  # resize video 2d frame size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is use_cuda True\n"
     ]
    }
   ],
   "source": [
    "# Detect devices\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "print(\"Is use_cuda\", use_cuda)\n",
    "# Now load the dataset\n",
    "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "# Load the dataset\n",
    "\n",
    "train_loader = data1.DataLoader(train_data, **params)\n",
    "valid_loader = data1.DataLoader(val_data, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_median(numpy_array = []): #This is expected to take an array of array. So,\n",
    "    #print(\"Input array is {}\".format(numpy_array))\n",
    "    output = []\n",
    "    confidence_scores = []\n",
    "    for array in numpy_array:\n",
    "        counts = np.bincount(array)\n",
    "        output.append(np.argmax(counts))\n",
    "        # Let us compute the confidence of the scores\n",
    "        # since frames are independent, our confidence is purely based on the number\n",
    "        # of frames our model thinks is belonging to a specific category\n",
    "        # the confidence of individual frame prediction is not taken into consideration\n",
    "        # and this portion is debatable....\n",
    "        frame_set_pred = np.sort(counts)[-1]\n",
    "        confidence = frame_set_pred/sum(counts)\n",
    "        confidence_scores.append(confidence)\n",
    "    return torch.from_numpy(np.asarray(output)).type(torch.LongTensor), torch.from_numpy(np.asarray(confidence_scores)).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model paths\n",
    "writer_train = SummaryWriter('/home/chinmay/training-results/conv3D_refined_2/train')\n",
    "writer_test = SummaryWriter('/home/chinmay/training-results/conv3D_refined_2/test')\n",
    "save_model_path = \"/home/chinmay/model_weights/conv3D_refined/\"\n",
    "\n",
    "\n",
    "\n",
    "# Select which frame to begin & end in videos\n",
    "begin_frame, end_frame, skip_frame = 1, 10, 1\n",
    "\n",
    "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
    "    # set model as training mode\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    scores = []\n",
    "    N_count = 0   # counting total trained sample in one epoch\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        #print(\"Shape of X is {}\".format(X.shape))\n",
    "        # distribute data to device\n",
    "        #X, y = X.to(device), y.to(device)\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        #print(\"The label is \",y)\n",
    "        N_count += X.size(0)\n",
    "        #print(\"The size is \",X.size())\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)  # output size = (batch, number of classes)\n",
    "        y, _ = find_median(y) #This is necessary as now only single label output for entire frame\n",
    "        y = y.to(device)\n",
    "        #print(y)\n",
    "        #print(y.shape)\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # to compute accuracy\n",
    "        y_pred = torch.max(output, 1)[1]  # y_pred != output\n",
    "        step_score = accuracy_score(y.cpu().data.squeeze().numpy(), y_pred.cpu().data.squeeze().numpy())\n",
    "        scores.append(step_score)         # computed on CPU\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "                 \n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accu: {:.2f}%'.format(\n",
    "                epoch + 1, N_count, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item(), 100 * step_score))\n",
    "         \n",
    "    return np.mean(losses), np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, device, optimizer, test_loader):\n",
    "    # set model as testing mode\n",
    "    model.eval()\n",
    "\n",
    "    all_y = []\n",
    "    all_y_pred = []\n",
    "    test_loss = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            # distribute data to device\n",
    "            #X, y = X.to(device), y.to(device)\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            output = model(X)\n",
    "\n",
    "            y, _ = find_median(y) #This is necessary as now only single label output for entire frame\n",
    "            y = y.to(device)\n",
    "            loss = F.cross_entropy(output, y)\n",
    "            test_loss.append(loss.item())                 # sum up batch loss\n",
    "            y_pred = output.max(1, keepdim=True)[1]  # (y_pred != output) get the index of the max log-probability\n",
    "            \n",
    "            # collect all y and y_pred in all batches\n",
    "            all_y.extend(y)\n",
    "            all_y_pred.extend(y_pred)\n",
    "\n",
    "    test_loss = np.mean(test_loss)\n",
    "\n",
    "    # to compute accuracy\n",
    "#     all_y = torch.stack(all_y, dim=0)\n",
    "#     all_y_pred = torch.stack(all_y_pred, dim=0)\n",
    "    all_y = torch.stack(all_y, dim=0)\n",
    "    all_y_pred = torch.stack(all_y_pred, dim=0)\n",
    "    test_score = accuracy_score(all_y.cpu().data.squeeze().numpy(), all_y_pred.cpu().data.squeeze().numpy())\n",
    "\n",
    "    # show information\n",
    "    print('\\nTest set ({:d} samples): Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(len(all_y), test_loss, 100* test_score))\n",
    "\n",
    "    # save Pytorch models of best record\n",
    "    torch.save(model.state_dict(), os.path.join(save_model_path, 'cnn3d{}.pth'.format(epoch + 1)))  # save spatial_encoder\n",
    "    torch.save(optimizer.state_dict(), os.path.join(save_model_path, 'cnn3d_epoch{}.pth'.format(epoch + 1)))      # save optimizer\n",
    "    print(\"Epoch {} model saved!\".format(epoch + 1))\n",
    "\n",
    "\n",
    "    return test_loss, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [40/416 (10%)]\tLoss: 0.271120, Accu: 100.00%\n",
      "Train Epoch: 1 [80/416 (19%)]\tLoss: 0.452481, Accu: 75.00%\n",
      "Train Epoch: 1 [120/416 (29%)]\tLoss: 0.490022, Accu: 75.00%\n",
      "Train Epoch: 1 [160/416 (38%)]\tLoss: 1.449256, Accu: 50.00%\n",
      "Train Epoch: 1 [200/416 (48%)]\tLoss: 0.882282, Accu: 50.00%\n",
      "Train Epoch: 1 [240/416 (58%)]\tLoss: 0.937742, Accu: 50.00%\n",
      "Train Epoch: 1 [280/416 (67%)]\tLoss: 0.897829, Accu: 50.00%\n",
      "Train Epoch: 1 [320/416 (77%)]\tLoss: 1.139328, Accu: 50.00%\n",
      "Train Epoch: 1 [360/416 (87%)]\tLoss: 1.362426, Accu: 50.00%\n",
      "Train Epoch: 1 [400/416 (96%)]\tLoss: 0.162122, Accu: 100.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.7853, Accuracy: 60.00%\n",
      "\n",
      "Epoch 1 model saved!\n",
      "Train Epoch: 2 [40/416 (10%)]\tLoss: 0.294280, Accu: 100.00%\n",
      "Train Epoch: 2 [80/416 (19%)]\tLoss: 0.530103, Accu: 75.00%\n",
      "Train Epoch: 2 [120/416 (29%)]\tLoss: 0.535219, Accu: 75.00%\n",
      "Train Epoch: 2 [160/416 (38%)]\tLoss: 0.931887, Accu: 50.00%\n",
      "Train Epoch: 2 [200/416 (48%)]\tLoss: 0.248920, Accu: 100.00%\n",
      "Train Epoch: 2 [240/416 (58%)]\tLoss: 0.566370, Accu: 75.00%\n",
      "Train Epoch: 2 [280/416 (67%)]\tLoss: 0.607998, Accu: 75.00%\n",
      "Train Epoch: 2 [320/416 (77%)]\tLoss: 0.598314, Accu: 75.00%\n",
      "Train Epoch: 2 [360/416 (87%)]\tLoss: 0.582837, Accu: 75.00%\n",
      "Train Epoch: 2 [400/416 (96%)]\tLoss: 0.653996, Accu: 75.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.5298, Accuracy: 73.62%\n",
      "\n",
      "Epoch 2 model saved!\n",
      "Train Epoch: 3 [40/416 (10%)]\tLoss: 0.553174, Accu: 50.00%\n",
      "Train Epoch: 3 [80/416 (19%)]\tLoss: 0.496233, Accu: 75.00%\n",
      "Train Epoch: 3 [120/416 (29%)]\tLoss: 0.282244, Accu: 100.00%\n",
      "Train Epoch: 3 [160/416 (38%)]\tLoss: 0.531540, Accu: 75.00%\n",
      "Train Epoch: 3 [200/416 (48%)]\tLoss: 0.473764, Accu: 50.00%\n",
      "Train Epoch: 3 [240/416 (58%)]\tLoss: 0.698433, Accu: 50.00%\n",
      "Train Epoch: 3 [280/416 (67%)]\tLoss: 0.244507, Accu: 100.00%\n",
      "Train Epoch: 3 [320/416 (77%)]\tLoss: 0.174439, Accu: 100.00%\n",
      "Train Epoch: 3 [360/416 (87%)]\tLoss: 0.652071, Accu: 50.00%\n",
      "Train Epoch: 3 [400/416 (96%)]\tLoss: 1.451827, Accu: 75.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.5548, Accuracy: 71.49%\n",
      "\n",
      "Epoch 3 model saved!\n",
      "Train Epoch: 4 [40/416 (10%)]\tLoss: 0.176888, Accu: 100.00%\n",
      "Train Epoch: 4 [80/416 (19%)]\tLoss: 0.124953, Accu: 100.00%\n",
      "Train Epoch: 4 [120/416 (29%)]\tLoss: 0.320375, Accu: 100.00%\n",
      "Train Epoch: 4 [160/416 (38%)]\tLoss: 0.377241, Accu: 75.00%\n",
      "Train Epoch: 4 [200/416 (48%)]\tLoss: 0.543539, Accu: 50.00%\n",
      "Train Epoch: 4 [240/416 (58%)]\tLoss: 0.380324, Accu: 75.00%\n",
      "Train Epoch: 4 [280/416 (67%)]\tLoss: 1.265872, Accu: 25.00%\n",
      "Train Epoch: 4 [320/416 (77%)]\tLoss: 0.496698, Accu: 50.00%\n",
      "Train Epoch: 4 [360/416 (87%)]\tLoss: 0.812007, Accu: 50.00%\n",
      "Train Epoch: 4 [400/416 (96%)]\tLoss: 0.346265, Accu: 100.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.7176, Accuracy: 66.38%\n",
      "\n",
      "Epoch 4 model saved!\n",
      "Train Epoch: 5 [40/416 (10%)]\tLoss: 0.305872, Accu: 100.00%\n",
      "Train Epoch: 5 [80/416 (19%)]\tLoss: 0.332275, Accu: 75.00%\n",
      "Train Epoch: 5 [120/416 (29%)]\tLoss: 0.404523, Accu: 75.00%\n",
      "Train Epoch: 5 [160/416 (38%)]\tLoss: 0.318313, Accu: 100.00%\n",
      "Train Epoch: 5 [200/416 (48%)]\tLoss: 0.316917, Accu: 75.00%\n",
      "Train Epoch: 5 [240/416 (58%)]\tLoss: 0.491731, Accu: 75.00%\n",
      "Train Epoch: 5 [280/416 (67%)]\tLoss: 0.422835, Accu: 75.00%\n",
      "Train Epoch: 5 [320/416 (77%)]\tLoss: 0.239998, Accu: 100.00%\n",
      "Train Epoch: 5 [360/416 (87%)]\tLoss: 0.414335, Accu: 75.00%\n",
      "Train Epoch: 5 [400/416 (96%)]\tLoss: 0.583321, Accu: 75.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.5315, Accuracy: 77.87%\n",
      "\n",
      "Epoch 5 model saved!\n",
      "Train Epoch: 6 [40/416 (10%)]\tLoss: 0.553101, Accu: 75.00%\n",
      "Train Epoch: 6 [80/416 (19%)]\tLoss: 0.171365, Accu: 100.00%\n",
      "Train Epoch: 6 [120/416 (29%)]\tLoss: 0.454073, Accu: 50.00%\n",
      "Train Epoch: 6 [160/416 (38%)]\tLoss: 0.422030, Accu: 75.00%\n",
      "Train Epoch: 6 [200/416 (48%)]\tLoss: 0.720283, Accu: 75.00%\n",
      "Train Epoch: 6 [240/416 (58%)]\tLoss: 0.254073, Accu: 100.00%\n",
      "Train Epoch: 6 [280/416 (67%)]\tLoss: 0.444338, Accu: 75.00%\n",
      "Train Epoch: 6 [320/416 (77%)]\tLoss: 0.372586, Accu: 100.00%\n",
      "Train Epoch: 6 [360/416 (87%)]\tLoss: 0.268103, Accu: 100.00%\n",
      "Train Epoch: 6 [400/416 (96%)]\tLoss: 0.824341, Accu: 25.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.5703, Accuracy: 76.60%\n",
      "\n",
      "Epoch 6 model saved!\n",
      "Train Epoch: 7 [40/416 (10%)]\tLoss: 0.962913, Accu: 25.00%\n",
      "Train Epoch: 7 [80/416 (19%)]\tLoss: 0.435563, Accu: 75.00%\n",
      "Train Epoch: 7 [120/416 (29%)]\tLoss: 0.764246, Accu: 50.00%\n",
      "Train Epoch: 7 [160/416 (38%)]\tLoss: 0.269731, Accu: 75.00%\n",
      "Train Epoch: 7 [200/416 (48%)]\tLoss: 0.476972, Accu: 75.00%\n",
      "Train Epoch: 7 [240/416 (58%)]\tLoss: 0.700490, Accu: 75.00%\n",
      "Train Epoch: 7 [280/416 (67%)]\tLoss: 0.200650, Accu: 100.00%\n",
      "Train Epoch: 7 [320/416 (77%)]\tLoss: 0.774886, Accu: 50.00%\n",
      "Train Epoch: 7 [360/416 (87%)]\tLoss: 0.386160, Accu: 100.00%\n",
      "Train Epoch: 7 [400/416 (96%)]\tLoss: 0.150686, Accu: 100.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.4560, Accuracy: 79.15%\n",
      "\n",
      "Epoch 7 model saved!\n",
      "Train Epoch: 8 [40/416 (10%)]\tLoss: 0.391630, Accu: 75.00%\n",
      "Train Epoch: 8 [80/416 (19%)]\tLoss: 0.161457, Accu: 100.00%\n",
      "Train Epoch: 8 [120/416 (29%)]\tLoss: 0.217967, Accu: 100.00%\n",
      "Train Epoch: 8 [160/416 (38%)]\tLoss: 0.355675, Accu: 75.00%\n",
      "Train Epoch: 8 [200/416 (48%)]\tLoss: 0.129882, Accu: 100.00%\n",
      "Train Epoch: 8 [240/416 (58%)]\tLoss: 0.568296, Accu: 50.00%\n",
      "Train Epoch: 8 [280/416 (67%)]\tLoss: 0.134468, Accu: 100.00%\n",
      "Train Epoch: 8 [320/416 (77%)]\tLoss: 0.172983, Accu: 100.00%\n",
      "Train Epoch: 8 [360/416 (87%)]\tLoss: 0.529465, Accu: 75.00%\n",
      "Train Epoch: 8 [400/416 (96%)]\tLoss: 0.417277, Accu: 100.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.5050, Accuracy: 76.60%\n",
      "\n",
      "Epoch 8 model saved!\n",
      "Train Epoch: 9 [40/416 (10%)]\tLoss: 0.282301, Accu: 100.00%\n",
      "Train Epoch: 9 [80/416 (19%)]\tLoss: 0.489720, Accu: 75.00%\n",
      "Train Epoch: 9 [120/416 (29%)]\tLoss: 0.535839, Accu: 75.00%\n",
      "Train Epoch: 9 [160/416 (38%)]\tLoss: 0.441480, Accu: 75.00%\n",
      "Train Epoch: 9 [200/416 (48%)]\tLoss: 0.460477, Accu: 75.00%\n",
      "Train Epoch: 9 [240/416 (58%)]\tLoss: 0.921482, Accu: 50.00%\n",
      "Train Epoch: 9 [280/416 (67%)]\tLoss: 0.127287, Accu: 100.00%\n",
      "Train Epoch: 9 [320/416 (77%)]\tLoss: 0.225589, Accu: 100.00%\n",
      "Train Epoch: 9 [360/416 (87%)]\tLoss: 0.204503, Accu: 100.00%\n",
      "Train Epoch: 9 [400/416 (96%)]\tLoss: 0.177987, Accu: 100.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.5446, Accuracy: 72.34%\n",
      "\n",
      "Epoch 9 model saved!\n",
      "Train Epoch: 10 [40/416 (10%)]\tLoss: 0.353781, Accu: 100.00%\n",
      "Train Epoch: 10 [80/416 (19%)]\tLoss: 0.363590, Accu: 75.00%\n",
      "Train Epoch: 10 [120/416 (29%)]\tLoss: 0.446116, Accu: 75.00%\n",
      "Train Epoch: 10 [160/416 (38%)]\tLoss: 0.232609, Accu: 100.00%\n",
      "Train Epoch: 10 [200/416 (48%)]\tLoss: 0.075304, Accu: 100.00%\n",
      "Train Epoch: 10 [240/416 (58%)]\tLoss: 0.522159, Accu: 75.00%\n",
      "Train Epoch: 10 [280/416 (67%)]\tLoss: 0.477880, Accu: 75.00%\n",
      "Train Epoch: 10 [320/416 (77%)]\tLoss: 0.962388, Accu: 50.00%\n",
      "Train Epoch: 10 [360/416 (87%)]\tLoss: 0.619438, Accu: 50.00%\n",
      "Train Epoch: 10 [400/416 (96%)]\tLoss: 0.379897, Accu: 75.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.5260, Accuracy: 74.47%\n",
      "\n",
      "Epoch 10 model saved!\n",
      "Train Epoch: 11 [40/416 (10%)]\tLoss: 0.565552, Accu: 75.00%\n",
      "Train Epoch: 11 [80/416 (19%)]\tLoss: 0.136086, Accu: 100.00%\n",
      "Train Epoch: 11 [120/416 (29%)]\tLoss: 0.571954, Accu: 75.00%\n",
      "Train Epoch: 11 [160/416 (38%)]\tLoss: 0.347524, Accu: 100.00%\n",
      "Train Epoch: 11 [200/416 (48%)]\tLoss: 0.675059, Accu: 75.00%\n",
      "Train Epoch: 11 [240/416 (58%)]\tLoss: 0.601022, Accu: 75.00%\n",
      "Train Epoch: 11 [280/416 (67%)]\tLoss: 1.222087, Accu: 50.00%\n",
      "Train Epoch: 11 [320/416 (77%)]\tLoss: 1.134108, Accu: 25.00%\n",
      "Train Epoch: 11 [360/416 (87%)]\tLoss: 0.359862, Accu: 75.00%\n",
      "Train Epoch: 11 [400/416 (96%)]\tLoss: 0.605840, Accu: 75.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.4172, Accuracy: 82.13%\n",
      "\n",
      "Epoch 11 model saved!\n",
      "Train Epoch: 12 [40/416 (10%)]\tLoss: 0.305236, Accu: 75.00%\n",
      "Train Epoch: 12 [80/416 (19%)]\tLoss: 0.445722, Accu: 75.00%\n",
      "Train Epoch: 12 [120/416 (29%)]\tLoss: 0.082479, Accu: 100.00%\n",
      "Train Epoch: 12 [160/416 (38%)]\tLoss: 0.919830, Accu: 75.00%\n",
      "Train Epoch: 12 [200/416 (48%)]\tLoss: 0.305359, Accu: 75.00%\n",
      "Train Epoch: 12 [240/416 (58%)]\tLoss: 1.492644, Accu: 50.00%\n",
      "Train Epoch: 12 [280/416 (67%)]\tLoss: 0.298861, Accu: 100.00%\n",
      "Train Epoch: 12 [320/416 (77%)]\tLoss: 0.343901, Accu: 75.00%\n",
      "Train Epoch: 12 [360/416 (87%)]\tLoss: 0.520536, Accu: 75.00%\n",
      "Train Epoch: 12 [400/416 (96%)]\tLoss: 0.333494, Accu: 100.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set (235 samples): Average loss: 0.4314, Accuracy: 79.57%\n",
      "\n",
      "Epoch 12 model saved!\n",
      "Train Epoch: 13 [40/416 (10%)]\tLoss: 0.203090, Accu: 100.00%\n",
      "Train Epoch: 13 [80/416 (19%)]\tLoss: 0.267791, Accu: 75.00%\n",
      "Train Epoch: 13 [120/416 (29%)]\tLoss: 0.721068, Accu: 75.00%\n",
      "Train Epoch: 13 [160/416 (38%)]\tLoss: 0.342566, Accu: 100.00%\n",
      "Train Epoch: 13 [200/416 (48%)]\tLoss: 0.215494, Accu: 100.00%\n",
      "Train Epoch: 13 [240/416 (58%)]\tLoss: 0.417917, Accu: 75.00%\n",
      "Train Epoch: 13 [280/416 (67%)]\tLoss: 1.194314, Accu: 50.00%\n",
      "Train Epoch: 13 [320/416 (77%)]\tLoss: 0.687885, Accu: 50.00%\n",
      "Train Epoch: 13 [360/416 (87%)]\tLoss: 0.173987, Accu: 100.00%\n",
      "Train Epoch: 13 [400/416 (96%)]\tLoss: 0.167501, Accu: 100.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.5693, Accuracy: 78.30%\n",
      "\n",
      "Epoch 13 model saved!\n",
      "Train Epoch: 14 [40/416 (10%)]\tLoss: 0.369195, Accu: 75.00%\n",
      "Train Epoch: 14 [80/416 (19%)]\tLoss: 0.127787, Accu: 100.00%\n",
      "Train Epoch: 14 [120/416 (29%)]\tLoss: 0.468968, Accu: 75.00%\n",
      "Train Epoch: 14 [160/416 (38%)]\tLoss: 0.228161, Accu: 100.00%\n",
      "Train Epoch: 14 [200/416 (48%)]\tLoss: 0.628767, Accu: 50.00%\n",
      "Train Epoch: 14 [240/416 (58%)]\tLoss: 0.219450, Accu: 75.00%\n",
      "Train Epoch: 14 [280/416 (67%)]\tLoss: 0.657164, Accu: 50.00%\n",
      "Train Epoch: 14 [320/416 (77%)]\tLoss: 0.233972, Accu: 75.00%\n",
      "Train Epoch: 14 [360/416 (87%)]\tLoss: 0.452302, Accu: 75.00%\n",
      "Train Epoch: 14 [400/416 (96%)]\tLoss: 0.548460, Accu: 50.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.5935, Accuracy: 80.43%\n",
      "\n",
      "Epoch 14 model saved!\n",
      "Train Epoch: 15 [40/416 (10%)]\tLoss: 0.234776, Accu: 100.00%\n",
      "Train Epoch: 15 [80/416 (19%)]\tLoss: 0.213195, Accu: 100.00%\n",
      "Train Epoch: 15 [120/416 (29%)]\tLoss: 0.560393, Accu: 75.00%\n",
      "Train Epoch: 15 [160/416 (38%)]\tLoss: 0.199844, Accu: 100.00%\n",
      "Train Epoch: 15 [200/416 (48%)]\tLoss: 0.354687, Accu: 75.00%\n",
      "Train Epoch: 15 [240/416 (58%)]\tLoss: 1.748801, Accu: 50.00%\n",
      "Train Epoch: 15 [280/416 (67%)]\tLoss: 0.149753, Accu: 100.00%\n",
      "Train Epoch: 15 [320/416 (77%)]\tLoss: 0.096578, Accu: 100.00%\n",
      "Train Epoch: 15 [360/416 (87%)]\tLoss: 0.206958, Accu: 100.00%\n",
      "Train Epoch: 15 [400/416 (96%)]\tLoss: 0.474691, Accu: 75.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.5068, Accuracy: 76.60%\n",
      "\n",
      "Epoch 15 model saved!\n",
      "Train Epoch: 16 [40/416 (10%)]\tLoss: 0.171880, Accu: 100.00%\n",
      "Train Epoch: 16 [80/416 (19%)]\tLoss: 0.458002, Accu: 75.00%\n",
      "Train Epoch: 16 [120/416 (29%)]\tLoss: 0.154043, Accu: 100.00%\n",
      "Train Epoch: 16 [160/416 (38%)]\tLoss: 0.537778, Accu: 75.00%\n",
      "Train Epoch: 16 [200/416 (48%)]\tLoss: 0.807601, Accu: 25.00%\n",
      "Train Epoch: 16 [240/416 (58%)]\tLoss: 2.029954, Accu: 25.00%\n",
      "Train Epoch: 16 [280/416 (67%)]\tLoss: 0.220122, Accu: 100.00%\n",
      "Train Epoch: 16 [320/416 (77%)]\tLoss: 0.133823, Accu: 100.00%\n",
      "Train Epoch: 16 [360/416 (87%)]\tLoss: 0.431952, Accu: 75.00%\n",
      "Train Epoch: 16 [400/416 (96%)]\tLoss: 0.387427, Accu: 100.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.4621, Accuracy: 79.57%\n",
      "\n",
      "Epoch 16 model saved!\n",
      "Train Epoch: 17 [40/416 (10%)]\tLoss: 0.449892, Accu: 75.00%\n",
      "Train Epoch: 17 [80/416 (19%)]\tLoss: 0.310342, Accu: 100.00%\n",
      "Train Epoch: 17 [120/416 (29%)]\tLoss: 0.543050, Accu: 50.00%\n",
      "Train Epoch: 17 [160/416 (38%)]\tLoss: 0.196058, Accu: 100.00%\n",
      "Train Epoch: 17 [200/416 (48%)]\tLoss: 0.302485, Accu: 75.00%\n",
      "Train Epoch: 17 [240/416 (58%)]\tLoss: 0.837844, Accu: 75.00%\n",
      "Train Epoch: 17 [280/416 (67%)]\tLoss: 0.239062, Accu: 75.00%\n",
      "Train Epoch: 17 [320/416 (77%)]\tLoss: 0.015764, Accu: 100.00%\n",
      "Train Epoch: 17 [360/416 (87%)]\tLoss: 0.213444, Accu: 100.00%\n",
      "Train Epoch: 17 [400/416 (96%)]\tLoss: 0.319042, Accu: 100.00%\n",
      "\n",
      "Test set (235 samples): Average loss: 0.5693, Accuracy: 79.15%\n",
      "\n",
      "Epoch 17 model saved!\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "#cnn3d = CNN3D(t_dim=10, img_x=img_x, img_y=img_y,\n",
    "#              drop_p=dropout, fc_hidden1=fc_hidden1,  fc_hidden2=fc_hidden2, num_classes=2)\n",
    "\n",
    "from Res3D import C3D\n",
    "cnn3d = C3D(img_dim=256, frames=30, dropout=0.25)\n",
    "# Comment this part...\n",
    "model_path = \"/home/chinmay/model_weights/conv3D_refined/\"\n",
    "weight_location = os.path.join(model_path,\"cnn3d4.pth\")\n",
    "cnn3d.load_state_dict(torch.load(weight_location))\n",
    "#\n",
    "\n",
    "cnn3d.cuda()\n",
    "# Parallelize model to multiple GPUs\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    cnn3d = nn.DataParallel(cnn3d)\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn3d.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
    "\n",
    "\n",
    "# record training process\n",
    "epoch_train_losses = []\n",
    "epoch_train_scores = []\n",
    "epoch_test_losses = []\n",
    "epoch_test_scores = []\n",
    "\n",
    "\n",
    "# start training\n",
    "for epoch in range(epochs):\n",
    "    # train, test model\n",
    "    train_losses, train_scores = train(log_interval, cnn3d, device, train_loader, optimizer, epoch)\n",
    "    epoch_test_loss, epoch_test_score = validation(cnn3d, device, optimizer, valid_loader)\n",
    "\n",
    "    # save all train test results\n",
    "    # save results\n",
    "    writer_train.add_scalar('loss',train_losses,epoch+1)\n",
    "    writer_train.add_scalar('score',train_scores,epoch+1)\n",
    "    writer_test.add_scalar('loss',epoch_test_loss,epoch+1)\n",
    "    writer_test.add_scalar('score',epoch_test_score,epoch+1)\n",
    "    \n",
    "    \n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
