{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data1\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "class Dataload_3D_CNN(data.Dataset):\n",
    "    \"Characterizes a dataset for PyTorch\"\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        \"Initialization\"\n",
    "        self.transform = transform\n",
    "        #self.frames = frames\n",
    "        self.folders = data_path\n",
    "\n",
    "    def __len__(self):\n",
    "        \"Denotes the total number of samples\"\n",
    "        return len(os.listdir(self.folders))\n",
    "\n",
    "    def read_images(self, data_path, use_transform):\n",
    "        X = []\n",
    "        for i in os.listdir(data_path):\n",
    "            #print(\"file name is \",i)\n",
    "            image = Image.open(os.path.join(data_path,i))\n",
    "            \n",
    "            #print(image.shape)\n",
    "            if use_transform is not None:\n",
    "                image = use_transform(image)\n",
    "                #print(image.size)\n",
    "            image = torch.from_numpy(np.asarray(image))\n",
    "            X.append(image)\n",
    "        #print(X)\n",
    "        #X = np.array(X)\n",
    "        X = torch.stack(X, dim=0)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"Generates one sample of data\"\n",
    "        # Select sample\n",
    "        #print(\"index passed is \",index)\n",
    "        #print(self.folders)\n",
    "        data_path = os.path.join(self.folders,os.listdir(self.folders)[index])\n",
    "        #data_path = self.folders+ str(index)\n",
    "        #print(\"Data path is \",data_path)\n",
    "        \n",
    "        # Load data\n",
    "        X = self.read_images(data_path, self.transform)                     # (input) spatial images\n",
    "        \n",
    "        y = 1\n",
    "        if 'orig' in data_path:\n",
    "            y = 0\n",
    "        # print(X.shape)\n",
    "        return X, torch.from_numpy(np.array(y)).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    #transforms.CenterCrop(256),\n",
    "    #transforms.ToTensor()\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         #std=[0.229, 0.224, 0.225] )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_path = '/home/chinmay/datatset/train/'\n",
    "train_data = Dataload_3D_CNN(train_path, transform=TRANSFORM_IMG)\n",
    "# for step, (x, y) in enumerate(data):\n",
    "#     print(x.shape)\n",
    "val_path = '/home/chinmay/datatset/val/'\n",
    "val_data = Dataload_3D_CNN(val_path, transform=TRANSFORM_IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 64\n",
    "learning_rate = 6 * 1e-5\n",
    "log_interval = 10\n",
    "img_x, img_y = 96,96#128,128#256, 256  # resize video 2d frame size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect devices\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "print(\"Is use_cuda\", use_cuda)\n",
    "# Now load the dataset\n",
    "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "# Load the dataset\n",
    "\n",
    "train_loader = data1.DataLoader(train_data, **params)\n",
    "valid_loader = data1.DataLoader(val_data, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path\n",
    "\n",
    "save_model_path = \"/home/chinmay/datatset/save_model/Conv3D_ckpt/\"  # save Pytorch models\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# 3D CNN parameters\n",
    "fc_hidden1, fc_hidden2 = 256, 256\n",
    "dropout = 0.0        # dropout probability\n",
    "\n",
    "\n",
    "# Select which frame to begin & end in videos\n",
    "begin_frame, end_frame, skip_frame = 1, 10, 1\n",
    "\n",
    "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
    "    # set model as training mode\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    scores = []\n",
    "    N_count = 0   # counting total trained sample in one epoch\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        # distribute data to device\n",
    "        #X, y = X.to(device), y.to(device)\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        #print(\"The label is \",y)\n",
    "        N_count += X.size(0)\n",
    "        #print(\"The size is \",X.size())\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)  # output size = (batch, number of classes)\n",
    "\n",
    "        loss = loss_function(output, y)\n",
    "        losses.append(loss.item())\n",
    "        #print(\"The loss is \",loss.item())\n",
    "        # to compute accuracy\n",
    "#         print(\"The output is \", output)\n",
    "        y_pred = torch.max(output,1)[1]\n",
    "        step_score = accuracy_score(y.cpu().data.squeeze().numpy(), y_pred.cpu().data.squeeze().numpy())\n",
    "        scores.append(step_score)         # computed on CPU\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # show information\n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accu: {:.2f}%'.format(\n",
    "                epoch + 1, N_count, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item(), 100 * step_score))\n",
    "        #torch.cuda.empty_cache()\n",
    "    return losses, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, device, optimizer, test_loader):\n",
    "    # set model as testing mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    all_y = []\n",
    "    all_y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            # distribute data to device\n",
    "            #X, y = X.to(device), y.to(device)\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            output = model(X)\n",
    "            y_pred = torch.max(output,1)[1]# (y_pred != output) get the index of the max log-probability\n",
    "            loss = loss_function(output, y)\n",
    "            test_loss += loss.item()                 # sum up batch loss\n",
    "            y_pred = torch.max(output,1)[1]                        \n",
    "            # torch.from_numpy(np.asarray(y_pred))\n",
    "            # collect all y and y_pred in all batches\n",
    "            all_y.extend(y)\n",
    "            all_y_pred.extend(y_pred)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # to compute accuracy\n",
    "#     all_y = torch.stack(all_y, dim=0)\n",
    "#     all_y_pred = torch.stack(all_y_pred, dim=0)\n",
    "    all_y = torch.from_numpy(np.asarray(all_y))\n",
    "    all_y_pred = torch.from_numpy(np.asarray(all_y_pred))\n",
    "    test_score = accuracy_score(all_y.cpu().data.squeeze().numpy(), all_y_pred.cpu().data.squeeze().numpy())\n",
    "\n",
    "    # show information\n",
    "    print('\\nTest set ({:d} samples): Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(len(all_y), test_loss, 100* test_score))\n",
    "\n",
    "    # save Pytorch models of best record\n",
    "    torch.save(model.state_dict(), os.path.join(save_model_path, '3dcnn_epoch{}.pth'.format(epoch + 1)))  # save spatial_encoder\n",
    "    torch.save(optimizer.state_dict(), os.path.join(save_model_path, '3dcnn_optimizer_epoch{}.pth'.format(epoch + 1)))      # save optimizer\n",
    "    print(\"Epoch {} model saved!\".format(epoch + 1))\n",
    "\n",
    "    return test_loss, test_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "##  Be careful in running this cell\n",
    "##  Skip it most of the times\n",
    "##########################################\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from Resnet import resnet10\n",
    "cnn3d = resnet10(sample_size = 128,in_channels = 10)\n",
    "pre_load = False\n",
    "model_name = \"3dcnn_epoch40.pth\"\n",
    "if pre_load:\n",
    "    model_path =  save_model_path + model_name\n",
    "    cnn3d.load_state_dict(torch.load(model_path))\n",
    "    save_model_path = save_model_path +\"temp/\"\n",
    "cnn3d.cuda()\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "#cnn3d = CNN3D(t_dim=10, img_x=img_x, img_y=img_y,\n",
    "#              drop_p=dropout, fc_hidden1=fc_hidden1,  fc_hidden2=fc_hidden2, num_classes=2)\n",
    "\n",
    "#print(cnn3d.conv1)\n",
    "# Parallelize model to multiple GPUs\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    cnn3d = nn.DataParallel(cnn3d)\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn3d.parameters(), lr=learning_rate, weight_decay =  1e-6)   # optimize all cnn parameters\n",
    "\n",
    "\n",
    "# record training process\n",
    "epoch_train_losses = []\n",
    "epoch_train_scores = []\n",
    "epoch_test_losses = []\n",
    "epoch_test_scores = []\n",
    "\n",
    "\n",
    "# start training\n",
    "for epoch in range(epochs):\n",
    "    # train, test model\n",
    "    #train_losses, train_scores = train(log_interval, cnn3d, device, train_loader, optimizer, epoch)\n",
    "    epoch_test_loss, epoch_test_score = validation(cnn3d, device, optimizer, valid_loader)\n",
    "    print(\"score is {}\".format(epoch_test_score))\n",
    "    # save results\n",
    "    epoch_train_losses.append(np.mean(train_losses))\n",
    "    epoch_train_scores.append(np.mean(train_scores))\n",
    "    epoch_test_losses.append(epoch_test_loss) #For validation set, it is already averaged\n",
    "    epoch_test_scores.append(epoch_test_score)\n",
    "    # save all train test results\n",
    "    A = np.array(epoch_train_losses)\n",
    "    B = np.array(epoch_train_scores)\n",
    "    C = np.array(epoch_test_losses)\n",
    "    D = np.array(epoch_test_scores)\n",
    "    np.save('./3DCNN_epoch_training_losses.npy', A)\n",
    "    np.save('./3DCNN_epoch_training_scores.npy', B)\n",
    "    np.save('./3DCNN_epoch_test_loss.npy', C)\n",
    "    np.save('./3DCNN_epoch_test_score.npy', D)\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "e = np.arange(1, epochs + 1)\n",
    "plt.plot(e,epoch_train_scores)\n",
    "plt.plot(e,epoch_test_scores)\n",
    "plt.legend(['train scores', 'validation scores'], loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "e = np.arange(1, epochs + 1)\n",
    "plt.plot(e,epoch_train_losses)\n",
    "plt.plot(e,epoch_test_losses)\n",
    "plt.legend(['train loss', 'validation loss'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing number of trainable parameters in the model\n",
    "model_parameters = filter(lambda p: p.requires_grad, cnn3d.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "e = np.arange(1, epochs + 1)\n",
    "plt.plot(e,epoch_train_scores)\n",
    "plt.plot(e,epoch_test_scores)\n",
    "plt.legend(['train scores', 'validation scores'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "e = np.arange(1, epochs + 1)\n",
    "plt.plot(e,epoch_train_losses)\n",
    "plt.plot(e,epoch_test_losses)\n",
    "plt.legend(['train loss', 'validation loss'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3d = resnet10()\n",
    "print(cnn3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
